import math
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import Tensor
from typing import Optional, Sequence, Tuple
from dataclasses import dataclass

torch.set_float32_matmul_precision('high')

# -----------------------------------------------------------------------------
# æ ¸å¿ƒç†å¿µï¼šé€™æ˜¯ä¸€å€‹ç‚ºæ“´æ•£æ¨¡å‹è¨­è¨ˆçš„U-Netï¼Œå…¶æ¶æ§‹ç¶“éé‡æ§‹ï¼Œä»¥èå…¥
# Flux Transformer çš„å¤šé …æ ¸å¿ƒè¨­è¨ˆç†å¿µã€‚å®ƒåœ¨ä¿æŒå·ç©U-Netéª¨å¹¹çš„åŒæ™‚ï¼Œ
# å¼•å…¥äº†å¦‚çµ±ä¸€æ¢ä»¶å‘é‡ã€æ¨¡å¡ŠåŒ–èª¿è£½ã€é›™æµèåˆæ³¨æ„åŠ›ã€QKæ­£è¦åŒ–ä»¥åŠ
# æ—‹è½‰ä½ç½®ç·¨ç¢¼(RoPE)ç­‰å…ˆé€²ç‰¹æ€§ã€‚
# -----------------------------------------------------------------------------


# ==============================================================================
# Section 1: åŸºç¤è¼”åŠ©æ¨¡å¡Š (Basic Helper Modules)
# ==============================================================================

@dataclass
class ModulationOut:
    """æ¸…æ™°åœ°å­˜å„²èª¿è£½åƒæ•¸"""
    shift: Tensor
    scale: Tensor
    gate: Tensor

def modulate(x: Tensor, shift: Tensor, scale: Tensor) -> Tensor:
    """æ‡‰ç”¨ adaLN èª¿è£½"""
    return x * (1 + scale.unsqueeze(-1).unsqueeze(-1)) + shift.unsqueeze(-1).unsqueeze(-1)

def rotate_half(x: torch.Tensor) -> torch.Tensor:
    """RoPE çš„æ ¸å¿ƒè¼”åŠ©å‡½æ•¸ï¼Œæ—‹è½‰ä¸€åŠçš„ç¶­åº¦"""
    x_reshaped = x.reshape(*x.shape[:-1], -1, 2)
    x_rotated_pairs = torch.cat([-x_reshaped[..., 1:], x_reshaped[..., :1]], dim=-1)
    return x_rotated_pairs.flatten(start_dim=-2)

class RMSNorm2d(nn.Module):
    """
    å‡æ–¹æ ¹å±¤æ­£è¦åŒ–ï¼Œä¿®æ­£å¾Œå¯æ­£ç¢ºè™•ç† 4D å·ç©ç‰¹å¾µåœ– (B, C, H, W)ã€‚
    """
    def __init__(self, dim: int, eps: float = 1e-6):
        super().__init__()
        self.eps = eps
        # scale çš„ç¶­åº¦æ˜¯é€šé“æ•¸ C
        self.scale = nn.Parameter(torch.ones(dim))

    def forward(self, x: Tensor) -> Tensor:
        # x çš„ shape æ˜¯ (B, C, H, W)
        # æˆ‘å€‘å¸Œæœ›åœ¨ channel (C) ç¶­åº¦ä¸Šé€²è¡Œæ­£è¦åŒ–
        # keepdim=True è®“ rrms çš„ shape ç‚º (B, 1, H, W) ä»¥ä¾¿å»£æ’­
        rrms = torch.rsqrt(x.pow(2).mean(dim=1, keepdim=True) + self.eps)

        # self.scale çš„ shape æ˜¯ (C,)
        # ç‚ºäº†èˆ‡ (B, C, H, W) çš„å¼µé‡ç›¸ä¹˜ï¼Œéœ€è¦ reshape æˆ (1, C, 1, 1)
        scale_reshaped = self.scale.view(1, -1, 1, 1)

        # (B,C,H,W) * (B,1,H,W) * (1,C,1,1) -> (B,C,H,W)
        return x * rrms * scale_reshaped

class QKNorm(nn.Module):
    """å°ˆé–€å° Query å’Œ Key é€²è¡Œæ­£è¦åŒ–çš„æ¨¡å¡Š"""
    def __init__(self, dim: int):
        super().__init__()
        self.query_norm = nn.RMSNorm(dim)
        self.key_norm = nn.RMSNorm(dim)

    def forward(self, q: Tensor, k: Tensor) -> tuple[Tensor, Tensor]:
        return self.query_norm(q), self.key_norm(k)

class Modulation(nn.Module):
    """å¾çµ±ä¸€çš„æ¢ä»¶å‘é‡ vec ç”Ÿæˆèª¿è£½åƒæ•¸"""
    def __init__(self, emb_dim: int, out_channels: int, is_double: bool = False):
        super().__init__()
        self.multiplier = 6 if is_double else 3
        self.lin = nn.Sequential(
            nn.SiLU(),
            nn.Linear(emb_dim, self.multiplier * out_channels, bias=True)
        )
        nn.init.zeros_(self.lin[-1].weight)
        nn.init.zeros_(self.lin[-1].bias)

    def forward(self, vec: Tensor) -> tuple[ModulationOut, Optional[ModulationOut]]:
        params = self.lin(vec)
        chunks = params.chunk(self.multiplier, dim=-1)
        mod1 = ModulationOut(shift=chunks[0], scale=chunks[1], gate=chunks[2])
        mod2 = ModulationOut(shift=chunks[3], scale=chunks[4], gate=chunks[5]) if self.multiplier == 6 else None
        return mod1, mod2

class Mlp(nn.Module):
    """ç©ºé–“ç‰¹å¾µçš„ MLP (ä½¿ç”¨1x1å·ç©å¯¦ç¾)"""
    def __init__(self, in_channels: int, hidden_channels: Optional[int] = None, act_layer: nn.Module = nn.GELU, drop: float = 0.0):
        super().__init__()
        hidden_channels = hidden_channels or in_channels * 4
        self.pw_conv1 = nn.Conv2d(in_channels, hidden_channels, 1)
        self.act = act_layer()
        self.pw_conv2 = nn.Conv2d(hidden_channels, in_channels, 1)
        self.drop = nn.Dropout(drop)

    def forward(self, x: Tensor) -> Tensor:
        return self.drop(self.pw_conv2(self.act(self.pw_conv1(x))))


# ==============================================================================
# Section 2: åµŒå…¥è¼”åŠ©æ¨¡å¡Š (Embedding Helpers)
# ==============================================================================

class SinusoidalPosEmb(nn.Module):
    """æ­£å¼¦ä½ç½®åµŒå…¥"""
    def __init__(self, embedding_dim: int, max_period: int = 10000, factor: float = 100.0):
        super().__init__()
        self.embedding_dim = embedding_dim if embedding_dim % 2 == 0 else embedding_dim + 1
        half_dim = self.embedding_dim // 2
        freqs = torch.exp(-math.log(max_period) * torch.arange(start=0, end=half_dim, dtype=torch.float32) / half_dim)
        self.register_buffer('freqs', freqs)
        self.factor = factor

    def forward(self, x: Tensor) -> Tensor:
        args = x.float().unsqueeze(1) * self.freqs.unsqueeze(0) * self.factor
        return torch.cat([torch.cos(args), torch.sin(args)], dim=-1)

class MLPEmbedder(nn.Module):
    """ç”¨æ–¼åµŒå…¥å‘é‡çš„MLP"""
    def __init__(self, embedding_dim: int):
        super().__init__()
        self.mlp = nn.Sequential(
            nn.Linear(embedding_dim, 4 * embedding_dim),
            nn.SiLU(),
            nn.Linear(4 * embedding_dim, embedding_dim),
        )

    def forward(self, x: Tensor) -> Tensor:
        return self.mlp(x)


# ==============================================================================
# Section 3: æ—‹è½‰ä½ç½®ç·¨ç¢¼ (RoPE Modules)
# ==============================================================================

class RoPE(nn.Module):
    """æ¨™æº–ä¸€ç¶­ RoPEï¼Œç”¨æ–¼æ¢ä»¶åºåˆ—"""
    def __init__(self, dim: int, base: int = 10000):
        super().__init__()
        assert dim % 2 == 0, "Dimension must be even"
        freqs = torch.arange(0, dim, 2, dtype=torch.float32) / dim
        inv_freq = 1.0 / (base**freqs)
        self.register_buffer("inv_freq", inv_freq)

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        seq_len = x.shape[-2]
        device = x.device
        positions = torch.arange(seq_len, device=device, dtype=torch.float32)
        freqs = torch.einsum("i,j->ij", positions, self.inv_freq)
        cos = freqs.cos().repeat_interleave(2, dim=-1)
        sin = freqs.sin().repeat_interleave(2, dim=-1)
        return x * cos + rotate_half(x) * sin

class RoPE_Mixed(nn.Module):
    """2D RoPEï¼Œç”¨æ–¼ç©ºé–“ç‰¹å¾µåœ–"""
    def __init__(self, dim: int):
        super().__init__()
        assert dim % 2 == 0, "Dimension must be even"
        self.freqs = nn.Parameter(torch.randn(dim // 2, 2))

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        H, W, D = x.shape[-3:]
        device = x.device
        grid_y, grid_x = torch.meshgrid(torch.arange(H, device=device), torch.arange(W, device=device), indexing="ij")
        positions_2d = torch.stack([grid_y.flatten(), grid_x.flatten()], dim=-1)

        theta_y = self.freqs[:, 0]
        theta_x = self.freqs[:, 1]
        angles = torch.einsum("n,d->nd", positions_2d[:, 0], theta_y) + torch.einsum("n,d->nd", positions_2d[:, 1], theta_x)

        cos_vals = angles.cos().repeat_interleave(2, dim=-1).reshape(H, W, D)
        sin_vals = angles.sin().repeat_interleave(2, dim=-1).reshape(H, W, D)

        while cos_vals.dim() < x.dim():
            cos_vals = cos_vals.unsqueeze(0)
            sin_vals = sin_vals.unsqueeze(0)

        return x * cos_vals + rotate_half(x) * sin_vals


# ==============================================================================
# Section 4: æ ¸å¿ƒ U-Net æ§‹å»ºå¡Š (Core U-Net Blocks)
# ==============================================================================

class FusedAttentionBlock(nn.Module):
    """é›™æµèåˆæ³¨æ„åŠ›æ¨¡å¡Š (ä¿®æ­£ç‰ˆï¼Œæ”¯æŒä¸åŒç¶­åº¦)"""
    def __init__(self, channels: int, emb_dim: int, num_heads: int, qkv_bias: bool = False):
        super().__init__()
        # ç§»é™¤ assert channels == emb_dim
        self.num_heads = num_heads
        self.head_dim = channels // num_heads
        assert self.head_dim * num_heads == channels, "channels å¿…é ˆèƒ½è¢« num_heads æ•´é™¤"

        self.to_qkv_spatial = nn.Conv2d(channels, channels * 3, 1, bias=qkv_bias)

        # --- ã€æ ¸å¿ƒä¿®æ­£ã€‘---
        # è®“æ¢ä»¶æµçš„ QKV æŠ•å°„è¼¸å‡ºç¶­åº¦èˆ‡ç©ºé–“æµå°é½Š (channels * 3)
        # é€™æ¨£å®ƒå€‘æ‰èƒ½è¢«åˆ‡åˆ†æˆç›¸åŒ head_dim çš„æ³¨æ„åŠ›é ­
        self.to_qkv_cond = nn.Linear(emb_dim, channels * 3, bias=qkv_bias)

        # RoPE å’Œ QKNorm çš„ç¶­åº¦éƒ½æ˜¯ head_dimï¼Œé€™éƒ¨åˆ†ä¸éœ€è¦æ”¹è®Š
        self.rope_spatial = RoPE_Mixed(self.head_dim)
        self.rope_conditional = RoPE(self.head_dim)
        self.qknorm = QKNorm(self.head_dim)

        self.to_out = nn.Linear(channels, channels)

    def forward(self, x: Tensor, cond_seq: Tensor) -> Tensor:
        # forward æ–¹æ³•çš„å…§éƒ¨é‚è¼¯å®Œå…¨ä¸éœ€è¦æ”¹è®Šï¼Œå› ç‚ºç¶­åº¦å·²ç¶“åœ¨ __init__ ä¸­å°é½Šäº†
        B, C, H, W = x.shape
        S = cond_seq.shape[1]

        q_s_raw, k_s_raw, v_s_raw = self.to_qkv_spatial(x).chunk(3, dim=1)
        qkv_c_raw = self.to_qkv_cond(cond_seq).reshape(B, S, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)
        q_c_raw, k_c_raw, v_c = qkv_c_raw[0], qkv_c_raw[1], qkv_c_raw[2]

        q_s_for_rope = q_s_raw.view(B, self.num_heads, self.head_dim, H, W).permute(0, 1, 3, 4, 2)
        k_s_for_rope = k_s_raw.view(B, self.num_heads, self.head_dim, H, W).permute(0, 1, 3, 4, 2)
        q_s_rot = self.rope_spatial(q_s_for_rope).permute(0, 1, 4, 2, 3).reshape(B, self.num_heads, C // self.num_heads, H * W).transpose(-1, -2)
        k_s_rot = self.rope_spatial(k_s_for_rope).permute(0, 1, 4, 2, 3).reshape(B, self.num_heads, C // self.num_heads, H * W).transpose(-1, -2)

        q_c_rot = self.rope_conditional(q_c_raw.reshape(B * self.num_heads, S, self.head_dim)).view(B, self.num_heads, S, self.head_dim)
        k_c_rot = self.rope_conditional(k_c_raw.reshape(B * self.num_heads, S, self.head_dim)).view(B, self.num_heads, S, self.head_dim)

        q = torch.cat((q_s_rot, q_c_rot), dim=2)
        k = torch.cat((k_s_rot, k_c_rot), dim=2)
        v_s = v_s_raw.view(B, self.num_heads, self.head_dim, H*W).transpose(-1,-2)
        v = torch.cat((v_s, v_c), dim=2)

        q, k = self.qknorm(q, k)

        attn_output = F.scaled_dot_product_attention(q, k, v)

        attn_spatial_output = attn_output[:, :, :H*W, :].transpose(1, 2).reshape(B, H * W, C)
        out = self.to_out(attn_spatial_output).permute(0, 2, 1).view(B, C, H, W)

        return out

class FluxlikeResnetBlock(nn.Module):
    """æ¨¡ä»¿ Flux/DiT è¨­è¨ˆçš„ ResNet å¡Š (æœ€çµ‚ç‰ˆ)"""
    def __init__(self, channels: int, emb_dim: int, num_heads: int, use_attention: bool, dropout: float, padding_mode: str):
        super().__init__()
        self.use_attention = use_attention
        self.modulation = Modulation(emb_dim, channels, is_double=True)
        self.norm1 = RMSNorm2d(channels)
        self.norm2 = RMSNorm2d(channels)

        if self.use_attention:
            self.op1 = FusedAttentionBlock(channels, emb_dim, num_heads)
        else:
            self.op1 = nn.Conv2d(channels, channels, 3, 1, 1, padding_mode=padding_mode, groups=channels)

        self.mlp = Mlp(channels, act_layer=lambda: nn.GELU(approximate="tanh"), drop=dropout)

    def forward(self, x: Tensor, cond_seq: Tensor, final_emb: Tensor) -> Tensor:
        mod1, mod2 = self.modulation(final_emb)
        h_mod = modulate(self.norm1(x), mod1.shift, mod1.scale)

        if self.use_attention:
            h_op1 = self.op1(h_mod, cond_seq)
        else:
            h_op1 = self.op1(h_mod)

        x = x + mod1.gate.unsqueeze(-1).unsqueeze(-1) * h_op1
        x = x + mod2.gate.unsqueeze(-1).unsqueeze(-1) * self.mlp(modulate(self.norm2(x), mod2.shift, mod2.scale))
        return x

class Downsample(nn.Module):
    """ä¸‹æ¡æ¨£ï¼šåŒæ™‚ç¸®å°å°ºå¯¸ä¸¦æ”¹è®Šé€šé“æ•¸"""
    def __init__(self, in_channels: int, out_channels: int, padding_mode: str):
        super().__init__()
        # ä½¿ç”¨ä¸€å€‹å·ç©å±¤åŒæ™‚å®Œæˆä¸‹æ¡æ¨£å’Œé€šé“è®Šæ›
        self.conv = nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=0)
        self.padding_mode = padding_mode

    def forward(self, x: Tensor, *args) -> Tensor: # å¢åŠ  *args ä»¥æ¥æ”¶å¤šé¤˜åƒæ•¸
        pad = (0, 1, 0, 1)
        pad_x = nn.functional.pad(x, pad, mode=self.padding_mode)
        return self.conv(pad_x)

class Upsample(nn.Module):
    """ä¸Šæ¡æ¨£ï¼šåŒæ™‚æ”¾å¤§å°ºå¯¸ä¸¦æ”¹è®Šé€šé“æ•¸"""
    def __init__(self, in_channels: int, out_channels: int, padding_mode: str):
        super().__init__()
        # å…ˆæ”¾å¤§å°ºå¯¸ï¼Œå†ç”¨å·ç©æ”¹è®Šé€šé“æ•¸
        self.upsample = nn.Upsample(scale_factor=2.0, mode="nearest")
        self.conv = nn.Conv2d(in_channels, out_channels, 3, padding=1, padding_mode=padding_mode)

    def forward(self, x: Tensor, *args) -> Tensor: # å¢åŠ  *args
        return self.conv(self.upsample(x))


# ==============================================================================
# Section 5: ä¸»æ¨¡å‹ (Main U-Net Model)
# ==============================================================================
@torch.compile
class FluxUNet(nn.Module):
    """æœ€çµ‚çš„ Flux-Style å·ç© U-Net (Decoder å’Œ Encoder é€šé“æµä¿®æ­£ç‰ˆ)"""
    def __init__(
        self,
        in_channels: int = 3,
        out_channels: int = 3,
        model_channels: int = 64,
        channel_mults: Sequence[int] = (1, 2, 4),
        num_blocks: int = 2,
        num_heads: int = 8,
        start_attn_level: int = 1,
        num_conditions: int = 1,
        dropout: float = 0.0,
        padding_mode: str = "replicate",
    ):
        super().__init__()
        self.emb_dim = model_channels
        self.num_conditions = num_conditions

        # --- åµŒå…¥å±¤ ---
        self.time_embedder = nn.Sequential(SinusoidalPosEmb(self.emb_dim, factor=1000), MLPEmbedder(self.emb_dim))
        if num_conditions > 0:
            self.cond_embedders = nn.ModuleList([
                nn.Sequential(SinusoidalPosEmb(self.emb_dim), MLPEmbedder(self.emb_dim))
                for _ in range(num_conditions)
            ])

        # --- ç¶²çµ¡çµæ§‹ ---
        self.conv_in = nn.Conv2d(in_channels, model_channels, 3, padding=1, padding_mode=padding_mode)
        block_args = {"emb_dim": self.emb_dim, "num_heads": num_heads, "dropout": dropout, "padding_mode": padding_mode}

        # 1. Encoder
        self.down_blocks = nn.ModuleList()
        ch_schedule = [model_channels] + [model_channels * m for m in channel_mults]

        for i in range(len(channel_mults)):
            level_modules = nn.ModuleList()
            ch_in = ch_schedule[i]
            ch_out = ch_schedule[i+1]
            for _ in range(num_blocks):
                level_modules.append(FluxlikeResnetBlock(channels=ch_in, use_attention=(i >= start_attn_level), **block_args))

            # ä½¿ç”¨ä¿®æ­£å¾Œçš„ Downsampleï¼Œæ­£ç¢ºåœ°å¾ ch_in è½‰æ›åˆ° ch_out
            level_modules.append(Downsample(in_channels=ch_in, out_channels=ch_out, padding_mode=padding_mode))
            self.down_blocks.append(level_modules)

        # 2. Bottleneck
        bottleneck_ch = ch_schedule[-1]
        self.middle_blocks = nn.ModuleList([
            FluxlikeResnetBlock(channels=bottleneck_ch, use_attention=True, **block_args),
            FluxlikeResnetBlock(channels=bottleneck_ch, use_attention=True, **block_args),
        ])

        # 3. Decoder
        self.up_blocks = nn.ModuleList()
        ch_schedule_rev = list(reversed(ch_schedule))

        for i in range(len(channel_mults)):
            ch_from_below = ch_schedule_rev[i]
            ch_from_skip = ch_schedule_rev[i+1]
            ch_out_level = ch_schedule_rev[i+1]

            level_modules = nn.ModuleDict()
            # Upsample å¾ ch_from_below è½‰æ›åˆ° ch_out_level
            level_modules['upsample'] = Upsample(in_channels=ch_from_below, out_channels=ch_out_level, padding_mode=padding_mode)
            # skip_proj åˆä½µå¾Œçš„é€šé“æ•¸æ˜¯ ch_out_level + ch_from_skip
            level_modules['skip_proj'] = nn.Conv2d(ch_out_level + ch_from_skip, ch_out_level, 1)

            level_blocks = nn.ModuleList()
            for _ in range(num_blocks):
                level_blocks.append(FluxlikeResnetBlock(channels=ch_out_level, use_attention=(len(channel_mults) - 1 - i >= start_attn_level), **block_args))
            level_modules['blocks'] = level_blocks
            self.up_blocks.append(level_modules)

        # 4. Final Output
        self.conv_out = nn.Sequential(
            RMSNorm2d(model_channels),
            nn.SiLU(),
            nn.Conv2d(model_channels, out_channels, 3, padding=1, padding_mode=padding_mode)
        )

    def forward(self, x: Tensor, time: Tensor, conditions: Optional[Sequence[Tensor]] = None) -> Tensor:
        # 1. æº–å‚™æ¢ä»¶å‘é‡ (é€™éƒ¨åˆ†é‚è¼¯æ˜¯æ­£ç¢ºçš„)
        t_emb = self.time_embedder(time.to(x.device))
        cond_seq_list, final_emb = [t_emb], t_emb.clone()
        if self.num_conditions > 0:
            for i, cond in enumerate(conditions):
                cond_emb = self.cond_embedders[i](cond.to(x.device))
                cond_seq_list.append(cond_emb)
                final_emb += cond_emb
        cond_seq = torch.stack(cond_seq_list, dim=1)

        # --- 2. U-Net å‰å‘å‚³æ’­ (ä¿®æ­£éƒ¨åˆ†) ---
        h = self.conv_in(x)
        skips = [h]

        # === Encoder ===
        # éæ­·æ¯ä¸€å±¤çš„æ¨¡å¡Šåˆ—è¡¨
        for level_modules in self.down_blocks:
            # level_modules æ˜¯ä¸€å€‹ ModuleListï¼Œæœ€å¾Œä¸€å€‹å…ƒç´ æ˜¯ Downsample
            res_blocks = level_modules[:-1]
            downsampler = level_modules[-1]

            # å…ˆè®“ h æµéé€™ä¸€å±¤æ‰€æœ‰çš„ ResBlock
            for block in res_blocks:
                h = block(h, cond_seq, final_emb)

            # ã€æ ¸å¿ƒä¿®æ­£ã€‘åœ¨ä¸‹æ¡æ¨£ä¹‹å‰ï¼Œä¿å­˜è·³èºé€£æ¥
            skips.append(h)

            # æœ€å¾ŒåŸ·è¡Œä¸‹æ¡æ¨£
            h = downsampler(h, cond_seq, final_emb)

        # === Bottleneck ===
        for block in self.middle_blocks:
            h = block(h, cond_seq, final_emb)

        # === Decoder ===
        # ç¾åœ¨ Decoder çš„é‚è¼¯æ˜¯å®Œå…¨æ­£ç¢ºçš„äº†
        for level_modules in self.up_blocks:
            # å¾ skips åˆ—è¡¨çš„æœ«å°¾å–å‡ºå°æ‡‰å±¤ç´šçš„ã€å°ºå¯¸æ­£ç¢ºçš„è·³èºé€£æ¥
            skip_h = skips.pop()

            # ä¸Šæ¡æ¨£ä¾†è‡ªä¸‹ä¸€å±¤çš„ h
            h = level_modules['upsample'](h, cond_seq, final_emb)

            # ç¾åœ¨ h å’Œ skip_h çš„ç©ºé–“å°ºå¯¸æ‡‰è©²å®Œå…¨åŒ¹é…
            h = torch.cat([h, skip_h], dim=1)

            # æŠ•å½±åˆä½µé€šé“
            h = level_modules['skip_proj'](h)

            # æµéé€™ä¸€å±¤çš„ ResBlock
            for block in level_modules['blocks']:
                h = block(h, cond_seq, final_emb)

        return self.conv_out(h)

# ==============================================================================
# Section 6: æ¸¬è©¦ä»£ç¢¼ (Testing Code)
# ==============================================================================

if __name__ == '__main__':
    # --- 1. åƒæ•¸è¨­å®š ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    batch_size = 2
    image_size = 32  # å¿…é ˆæ˜¯ 2^num_levels çš„å€æ•¸
    in_channels = 3
    out_channels = 3
    model_channels = 64
    channel_mults = (1, 2, 2)  # 3 å€‹ U-Net å±¤ç´š
    num_blocks = 2
    num_heads = 4
    start_attn_level = 1 # ç¬¬ 0 å±¤ (æœ€å¤–å±¤) ä¸ç”¨ attentionï¼Œç¬¬ 1, 2 å±¤ç”¨
    num_conditions = 1 # 1 å€‹é¡å¤–æ¢ä»¶

    # --- 2. å‰µå»ºæ¨¡å‹ ---
    print("ğŸš€ æ­£åœ¨å‰µå»º Flux-Style U-Net æ¨¡å‹...")
    model = FluxUNet(
        in_channels=in_channels,
        out_channels=out_channels,
        model_channels=model_channels,
        channel_mults=channel_mults,
        num_blocks=num_blocks,
        num_heads=num_heads,
        start_attn_level=start_attn_level,
        num_conditions=num_conditions
    ).to(device)

    # æ‰“å°æ¨¡å‹åƒæ•¸æ•¸é‡
    num_params = sum(p.numel() for p in model.parameters())
    print(f"âœ… æ¨¡å‹å‰µå»ºæˆåŠŸï¼")
    print(f"   - ç¸½åƒæ•¸æ•¸é‡: {num_params / 1e6:.2f} M")
    print(f"   - é‹è¡Œè¨­å‚™: {device.type.upper()}")

    # --- 3. æº–å‚™è™›æ“¬è¼¸å…¥æ•¸æ“š ---
    print("\nğŸ“¦ æ­£åœ¨æº–å‚™è™›æ“¬è¼¸å…¥æ•¸æ“š...")

    # åœ–åƒè¼¸å…¥
    x = torch.randn(batch_size, in_channels, image_size, image_size, device=device)

    # æ™‚é–“æ­¥è¼¸å…¥
    time = torch.randint(0, 1000, (batch_size,), device=device)

    # é¡å¤–æ¢ä»¶è¼¸å…¥ (ä¾‹å¦‚é¡åˆ¥æ¨™ç±¤ã€CFGå¼·åº¦ç­‰)
    # é€™è£¡ç”¨ä¸€å€‹éš¨æ©Ÿå€¼æ¨¡æ“¬
    cond1 = torch.randint(0, 10, (batch_size,), device=device)
    conditions = [cond1]

    print("   - åœ–åƒè¼¸å…¥ shape:    ", x.shape)
    print("   - æ™‚é–“æ­¥è¼¸å…¥ shape:  ", time.shape)
    print("   - æ¢ä»¶è¼¸å…¥ shape:    ", [c.shape for c in conditions])

    # --- 4. åŸ·è¡Œå‰å‘å‚³æ’­æ¸¬è©¦ ---
    print("\nâš¡ï¸ æ­£åœ¨åŸ·è¡Œå‰å‘å‚³æ’­æ¸¬è©¦...")
    try:
        with torch.no_grad(): # æ¸¬è©¦æ™‚ä¸éœ€è¦è¨ˆç®—æ¢¯åº¦
            output = model(x, time, conditions)

        print("âœ… å‰å‘å‚³æ’­æˆåŠŸï¼")
        print(f"   - è¼¸å‡º shape: {output.shape}")

        # æª¢æŸ¥è¼¸å‡º shape æ˜¯å¦èˆ‡è¼¸å…¥ shape ä¸€è‡´
        assert output.shape == x.shape, "è¼¸å‡º shape èˆ‡è¼¸å…¥ shape ä¸åŒ¹é…ï¼"
        print("   - è¼¸å‡º shape é©—è­‰æˆåŠŸï¼")

    except Exception as e:
        print(f"âŒ å‰å‘å‚³æ’­å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()